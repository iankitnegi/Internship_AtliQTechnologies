# Internship @ AtliQ Technologies  
As a Data Analyst Intern at AtliQ Technologies, I will work with experienced professionals to analyze data, create reports, and provide insights that will aid in making informed business decisions. This internship will be conducted remotely and will provide all the necessary tools and resources to help me succeed in this role.  

## WEEK 1:  

> ### E-Mail:  
> **HR REPORT**  
Sending you these tasks following up on our call.   
The HR dataset can be found in the file "attendance_data.csv". Your tasks are divided into two parts: data cleaning and data analysis.
>
> Task 1: Data Cleaning
> - Standardize the date values to the format YYYY-MM-DD and extract the month name and day type from them.
> - Remove any extra characters, such as special characters, from the employee ID values. Some IDs may contain a '@' character at the end, which can be cleaned and brought to a common format.
> - Standardize the capitalization of names. Convert all names to title case, which means capitalizing the first letter of each word.
> - Map the corresponding values in the status column with the given abbreviations:  
>    - Work From Office --> WFO
>    - Work From Home --> WFH
>    - Birthday Leave --> BL
>    - Menstrual Leave --> ML
>    - Paid Leave --> PL
>    - Sick Leave --> SL
>    - Weekly Off --> WO  
> - Check for duplicates in the dataset and remove them.
>   
> Task 2: Ad Hoc aka Analysis  
> - What is the total count of distinct employee names within the dataset?
> - Calculate the work-from-home (WFH %) percentage in the month of May?
> - Determine which day of the week had the highest attendance percentage in the month of June?
> - Find out the number of employees who had a WFH percentage greater than 10% in the month of April?  
>
> You are free to use any tool of your preference, such as Pandas, Excel, PowerBI, etc., to complete this task.  
Good luck with your task!  
Best regards,  
Hem  
Head of Data Analytics

#### **Solution on:** File name: attendance_data_soln

> ### E-Mail:  
> **DATA NORMALIZATION TASK**  
> Well done with the previous task. I have a new one for you.  
One of our client projects requires a minor support. The dataset is currently in a de-normalized form, and we need your help to transform it into a normalized form.  
Your task will involve creating proper fact and dimension tables based on the dataset, which can be found in the "fact_order_lines.csv" file. Providing a few screenshots of the dataset below, which will give you a better idea of what it looks like and how the final output should be presented
> ![image](https://github.com/iankitnegi/Internship_AtliQ_Technologies/assets/132642567/ba151cad-6528-4b86-a1c6-0f81a01088a2)
> <img width="353" alt="task2_2" src="https://github.com/iankitnegi/Internship_AtliQ_Technologies/assets/132642567/39b1da56-74af-4405-a2b6-f8ef858113ab">    <img width="351" alt="task2_3" src="https://github.com/iankitnegi/Internship_AtliQ_Technologies/assets/132642567/0c8dda5a-e866-451a-ab34-b9b9af48ab10">

#### **Solution on:** File name: fact_order_soln



